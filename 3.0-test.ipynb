{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import Adadelta, RMSprop, SGD, Adam\n",
    "from keras.layers import (\n",
    "    Input,\n",
    "    Conv1D,\n",
    "    GlobalAveragePooling1D,\n",
    "    MaxPooling1D,\n",
    "    Flatten,\n",
    "    Activation,\n",
    "    UpSampling1D,\n",
    "    AveragePooling1D,\n",
    "    Reshape,\n",
    ")\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.utils import to_categorical\n",
    "from keras.losses import categorical_crossentropy, binary_crossentropy\n",
    "\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data and normalize\n",
    "def normalizer(a, min_val, max_val):\n",
    "    # min-max scaling if wanted\n",
    "    # https://codereview.stackexchange.com/questions/185785/scale-numpy-array-to-certain-range\n",
    "    col, row = np.shape(a)\n",
    "    for i in range(col):\n",
    "        a[i] = np.interp(a[i], (min_val, max_val), (0, 1))\n",
    "    return a\n",
    "\n",
    "\n",
    "# Load Pickles\n",
    "\n",
    "# all_train\n",
    "pickle_in = open(\"all_train_mean_NOSCALE.pickle\", \"rb\")\n",
    "X_all = pickle.load(pickle_in)\n",
    "\n",
    "# df_extra1\n",
    "pickle_in = open(\"df_extra1_mean_NOSCALE.pickle\", \"rb\")\n",
    "X_extra1 = pickle.load(pickle_in)\n",
    "\n",
    "# df_extra2\n",
    "pickle_in = open(\"df_extra2_mean_NOSCALE.pickle\", \"rb\")\n",
    "X_extra2 = pickle.load(pickle_in)\n",
    "\n",
    "# df_extra3\n",
    "pickle_in = open(\"df_extra3_mean_NOSCALE.pickle\", \"rb\")\n",
    "X_extra3 = pickle.load(pickle_in)\n",
    "\n",
    "# X_train\n",
    "pickle_in = open(\"X_train.pickle\", \"rb\")\n",
    "X_train = pickle.load(pickle_in)\n",
    "\n",
    "# X_val\n",
    "pickle_in = open(\"X_val.pickle\", \"rb\")\n",
    "X_val = pickle.load(pickle_in)\n",
    "\n",
    "# X_test\n",
    "pickle_in = open(\"X_test.pickle\", \"rb\")\n",
    "X_test = pickle.load(pickle_in)\n",
    "\n",
    "# y_train\n",
    "pickle_in = open(\"y_train.pickle\", \"rb\")\n",
    "y_train = pickle.load(pickle_in)\n",
    "\n",
    "# y_val\n",
    "pickle_in = open(\"y_val.pickle\", \"rb\")\n",
    "y_val = pickle.load(pickle_in)\n",
    "\n",
    "# y_test\n",
    "pickle_in = open(\"y_test.pickle\", \"rb\")\n",
    "y_test = pickle.load(pickle_in)\n",
    "\n",
    "X_all = np.concatenate((X_all, X_extra1, X_extra2, X_extra3), axis=0)\n",
    "\n",
    "X_kaggle = np.concatenate((X_extra1, X_extra2, X_extra3), axis=0)\n",
    "                 \n",
    "# If needed, normalize the data between 0-1\n",
    "min_all = X_all.min()\n",
    "max_all = X_all.max()\n",
    "\n",
    "X_all = normalizer(X_all, min_all, max_all)\n",
    "X_train = normalizer(X_train, min_all, max_all)\n",
    "X_val = normalizer(X_val, min_all, max_all)\n",
    "X_test = normalizer(X_test, min_all, max_all)\n",
    "X_kaggle = normalizer(X_kaggle, min_all, max_all)\n",
    "\n",
    "# Reshape\n",
    "X_all = X_all.reshape([-1, 800, 1]).astype(\"float32\")\n",
    "X_train = X_train.reshape([-1, 800, 1]).astype(\"float32\")\n",
    "X_val = X_val.reshape([-1, 800, 1]).astype(\"float32\")\n",
    "X_test = X_test.reshape([-1, 800, 1]).astype(\"float32\")\n",
    "X_kaggle = X_kaggle.reshape([-1, 800, 1]).astype(\"float32\")\n",
    "                 \n",
    "# split X_all data\n",
    "X_all_train, X_all_val, y_junk, y_junk = train_test_split(\n",
    "    X_all, X_all, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Primary Model: Predict on Test Set for MEAN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = '/home/tim/Documents/PD-Predictions/notebooks/fc_final/FC_mean_GLOBAL_FALSE-327501p-3e_kern-64e_filt-16pool_size-3d_kern-64d_filt-20fc_units-2fc_layers-0.2dropout_val-1554569587'\n",
    "model_save = 'epoch.236-val_loss.0.50.h5'\n",
    "path = os.path.join('/home/tim/Documents/PD-Predictions/notebooks/fc_final/',model_name)\n",
    "\n",
    "\n",
    "file_path = os.path.join(path,model_save)\n",
    "\n",
    "model = keras.models.load_model(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 1s 7ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5025882834841491, 0.7452229348717222]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = model.evaluate(X_val, y_val)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158/158 [==============================] - 0s 832us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6046233516705187, 0.7468354392655289]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Baseline Model (simple CNN): Predict on Test Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = '/home/tim/Documents/PD-Predictions/notebooks/cnn_simple/CNN-1235-5kern-30filt-1conv_layer-3kernel2-10filter2-16pool_size-12fc_units-1fc_layers-0dropout_val-1553914440'\n",
    "model_save = 'epoch.6869-val_loss.0.45.h5'\n",
    "path = os.path.join('/home/tim/Documents/PD-Predictions/notebooks/cnn_simple',model_name)\n",
    "\n",
    "\n",
    "file_path = os.path.join(path,model_save)\n",
    "\n",
    "model = keras.models.load_model(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 521us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.44926111789266016, 0.8025477756360534]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = model.evaluate(X_val, y_val)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158/158 [==============================] - 0s 65us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6241879285890845, 0.7531645531895794]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test)\n",
    "score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
